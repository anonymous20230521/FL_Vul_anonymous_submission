{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "57ef6752-ecf2-40df-8e76-20fdf20850e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x2b5727fd6890>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "from img2vec_pytorch import Img2Vec\n",
    "import os\n",
    "import glob\n",
    "# for reproducibility\n",
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "584f6796-e6f2-4fcc-bad7-1258f123cec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "if device == 'cuda':\n",
    "    torch.backends.cudnn.benchmark=True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df015bcd-93ea-490e-bdf8-c9817f27147a",
   "metadata": {},
   "source": [
    "# Misc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "77571004-7836-4eec-9444-e995677da619",
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "NUM_PROCESS = 2\n",
    "\n",
    "def unpacking_apply_along_axis(all_args):\n",
    "    (func1d, axis, arr, args, kwargs) = all_args\n",
    "    \n",
    "    \"\"\"\n",
    "    Like numpy.apply_along_axis(), but with arguments in a tuple\n",
    "    instead.\n",
    "\n",
    "    This function is useful with multiprocessing.Pool().map(): (1)\n",
    "    map() only handles functions that take a single argument, and (2)\n",
    "    this function can generally be imported from a module, as required\n",
    "    by map().\n",
    "    \"\"\"\n",
    "    return np.apply_along_axis(func1d, axis, arr, *args, **kwargs)\n",
    "\n",
    "def parallel_apply_along_axis(func1d, axis, arr, *args, **kwargs):\n",
    "    \"\"\"\n",
    "    Like numpy.apply_along_axis(), but takes advantage of multiple\n",
    "    cores.\n",
    "    \"\"\"        \n",
    "    # Effective axis where apply_along_axis() will be applied by each\n",
    "    # worker (any non-zero axis number would work, so as to allow the use\n",
    "    # of `np.array_split()`, which is only done on axis 0):\n",
    "    effective_axis = 1 if axis == 0 else axis\n",
    "    if effective_axis != axis:\n",
    "        arr = arr.swapaxes(axis, effective_axis)\n",
    "\n",
    "    # Chunks for the mapping (only a few chunks):\n",
    "    chunks = [(func1d, effective_axis, sub_arr, args, kwargs)\n",
    "              for sub_arr in np.array_split(arr, NUM_PROCESS)]\n",
    "    \n",
    "    # print(chunks)\n",
    "\n",
    "    pool = multiprocessing.Pool(processes=NUM_PROCESS)\n",
    "    individual_results = pool.map(unpacking_apply_along_axis, chunks)\n",
    "    \n",
    "    # Freeing the workers:\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "    \n",
    "    # print(individual_results)\n",
    "\n",
    "    return np.concatenate(individual_results)\n",
    "\n",
    "\n",
    "# def unpacking_matrix_operation(all_args)\n",
    "#     (func, sub_arr) = \n",
    "\n",
    "def parallel_matrix_operation(func, arr):\n",
    "    # chunks = [(func, sub_arr) for sub_arr in np.array_split(arr, NUM_PROCESS)]\n",
    "    chunks = np.array_split(arr, NUM_PROCESS)\n",
    "    \n",
    "    \n",
    "    pool = multiprocessing.Pool(processes=NUM_PROCESS)\n",
    "    individual_results = pool.map(func, chunks)\n",
    "    \n",
    "    # Freeing the workers:\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "    \n",
    "    # print(individual_results)\n",
    "\n",
    "    return np.concatenate(individual_results)\n",
    "\n",
    "def tpr_tnr(prediction, truth):\n",
    "    \"\"\" Returns the confusion matrix for the values in the `prediction` and `truth`\n",
    "    tensors, i.e. the amount of positions where the values of `prediction`\n",
    "    and `truth` are\n",
    "    - 1 and 1 (True Positive)\n",
    "    - 1 and 0 (False Positive)\n",
    "    - 0 and 0 (True Negative)\n",
    "    - 0 and 1 (False Negative)\n",
    "    \"\"\"\n",
    "\n",
    "    confusion_vector = prediction / truth\n",
    "    # Element-wise division of the 2 tensors returns a new tensor which holds a\n",
    "    # unique value for each case:\n",
    "    #   1     where prediction and truth are 1 (True Negative)\n",
    "    #   inf   where prediction is 1 and truth is 0 (False Negative)\n",
    "    #   nan   where prediction and truth are 0 (True Positive)\n",
    "    #   0     where prediction is 0 and truth is 1 (False Positive)\n",
    "    \n",
    "    true_negatives = torch.sum(confusion_vector == 1).item()\n",
    "    false_negatives = torch.sum(confusion_vector == float('inf')).item()\n",
    "    true_positives = torch.sum(torch.isnan(confusion_vector)).item()\n",
    "    false_positives = torch.sum(confusion_vector == 0).item()\n",
    "\n",
    "    # print(true_negatives, false_negatives, true_positives, false_positives)\n",
    "    return true_positives / (true_positives + false_negatives), true_negatives / (true_negatives + false_positives), (true_positives + true_negatives) / (true_negatives + false_negatives + true_positives + false_positives)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47b5e90c-0b88-4136-afb7-c105ec3d5045",
   "metadata": {},
   "source": [
    "# LDP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6a196fc6-b31c-4fdc-abe7-3b9ce069c500",
   "metadata": {},
   "outputs": [],
   "source": [
    "l = 20\n",
    "m = 5\n",
    "r = 512\n",
    "\n",
    "def float_to_binary(x, m, n):\n",
    "    x_abs = np.abs(x)\n",
    "    x_scaled = round(x_abs * 2 ** n)\n",
    "    res = '{:0{}b}'.format(x_scaled, m + n)\n",
    "    if x >= 0:\n",
    "        res = '0' + res\n",
    "    else:\n",
    "        res = '1' + res\n",
    "    return res\n",
    "\n",
    "# binary to float\n",
    "def binary_to_float(bstr, m, n):\n",
    "    sign = bstr[0]\n",
    "    # print(int(sign))\n",
    "    bs = bstr[1:]\n",
    "    res = int(bs, 2) / 2 ** n\n",
    "    if int(sign) == 49:\n",
    "        res = -1 * res\n",
    "    return res\n",
    "\n",
    "def string_to_int(a):\n",
    "    bit_str = \"\".join(x for x in a)\n",
    "    return np.array(list(bit_str)).astype(int)\n",
    "\n",
    "\n",
    "def join_string(a, num_bit=l, num_feat=r):\n",
    "    res = np.empty(num_feat, dtype=\"S20\")\n",
    "    # res = []\n",
    "    for i in range(num_feat):\n",
    "        # res.append(\"\".join(str(x) for x in a[i*l:(i+1)*l]))\n",
    "        res[i] = \"\".join(str(x) for x in a[i*l:(i+1)*l])\n",
    "    return res\n",
    "\n",
    "\n",
    "def float_bin(x):\n",
    "    return float_to_binary(x, m, l-m-1)\n",
    "    \n",
    "\n",
    "def bin_float(x):\n",
    "    return binary_to_float(x, m, l-m-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "39b23197-0521-4596-b844-04a4fda73740",
   "metadata": {},
   "outputs": [],
   "source": [
    "def BitRand(sample_feature_arr, eps=20.0, l=5, m=m):\n",
    "\n",
    "    r = sample_feature_arr.shape[1]\n",
    "    \n",
    "    float_to_binary_vec = np.vectorize(float_bin)\n",
    "    binary_to_float_vec = np.vectorize(bin_float)\n",
    "\n",
    "    feat_tmp = parallel_matrix_operation(float_to_binary_vec, sample_feature_arr)\n",
    "    feat = parallel_apply_along_axis(string_to_int, axis=1, arr=feat_tmp)\n",
    "\n",
    "    rl = r * l\n",
    "    sum_ = 0\n",
    "    for k in range(l):\n",
    "        sum_ += np.exp(2 * eps*k /l)\n",
    "    alpha = np.sqrt((eps + rl) /( 2*r *sum_ ))\n",
    "    index_matrix = np.array(range(l))\n",
    "    index_matrix = np.tile(index_matrix, (sample_feature_arr.shape[0], r))\n",
    "    p =  1/(1+alpha * np.exp(index_matrix*eps/l) )\n",
    "    p_temp = np.random.rand(p.shape[0], p.shape[1])\n",
    "    perturb = (p_temp > p).astype(int)\n",
    "\n",
    "    perturb_feat = (perturb + feat)%2\n",
    "    perturb_feat = parallel_apply_along_axis(join_string, axis=1, arr=perturb_feat)\n",
    "    # print(perturb_feat)\n",
    "    return torch.tensor(parallel_matrix_operation(binary_to_float_vec, perturb_feat), dtype=torch.float)\n",
    "\n",
    "def BitRand_1(sample_feature_arr, eps, l=20, m=5, r=512):\n",
    "    float_bin_2 = lambda x: float_to_binary(x, m, l-m-1)\n",
    "    float_to_binary_vec_2 = np.vectorize(float_bin_2)\n",
    "    bin_float_2 = lambda x: binary_to_float(x, m, l-m-1)\n",
    "    binary_to_float_vec_2 = np.vectorize(bin_float_2)\n",
    "\n",
    "    feat_tmp = float_to_binary_vec_2(sample_feature_arr)\n",
    "    feat = np.apply_along_axis(string_to_int, axis=1, arr=feat_tmp)\n",
    "    sum_ = 0\n",
    "    for k in range(l):\n",
    "        sum_ += np.exp(2 * eps*k /l)\n",
    "    alpha = np.sqrt((eps + r*l) /( 2*r *sum_ ))\n",
    "\n",
    "    index_matrix = np.array(range(l))\n",
    "    index_matrix = np.tile(index_matrix, (1, r))\n",
    "    p =  1/(1+alpha * np.exp(index_matrix*eps/l) )\n",
    "    p_temp = np.random.rand(p.shape[0], p.shape[1])\n",
    "    perturb = (p_temp > p).astype(int)\n",
    "    perturb_feat = (perturb + feat)%2\n",
    "    perturb_feat = np.apply_along_axis(join_string, axis=1, arr=perturb_feat)\n",
    "    perturb_feat = binary_to_float_vec_2(perturb_feat)\n",
    "    return torch.squeeze(torch.tensor(perturb_feat, dtype=torch.float))#.cuda()\n",
    "\n",
    "def OME(sample_feature_arr, eps=10.0, l=20, m=5):\n",
    "    r = sample_feature_arr.shape[1]\n",
    "    \n",
    "    float_to_binary_vec = np.vectorize(float_bin)\n",
    "    binary_to_float_vec = np.vectorize(bin_float)\n",
    "\n",
    "    feat_tmp = parallel_matrix_operation(float_to_binary_vec, sample_feature_arr)\n",
    "    feat = parallel_apply_along_axis(string_to_int, axis=1, arr=feat_tmp)\n",
    "\n",
    "    rl = r * l\n",
    "    alpha_ome = 100\n",
    "    index_matrix_1 = np.array([alpha_ome / (1+ alpha_ome), 1/ (1+alpha_ome**3)]*int(l/2)) # np.array(range(l))\n",
    "    index_matrix_0 = np.array([ (alpha_ome * np.exp(eps/rl)) /(1 + alpha_ome* np.exp(eps/rl))]*int(l) )\n",
    "    p_1 = np.tile(index_matrix_1, (sample_feature_arr.shape[0], r))\n",
    "    p_0 = np.tile(index_matrix_0, (sample_feature_arr.shape[0], r))\n",
    "\n",
    "    p_temp = np.random.rand(p_0.shape[0], p_0.shape[1])\n",
    "    perturb_0 = (p_temp > p_0).astype(int)\n",
    "    perturb_1 = (p_temp > p_1).astype(int)\n",
    "\n",
    "    perturb_feat = np.array(torch.where(torch.tensor(feat)>0, torch.tensor((perturb_1 + feat)%2), torch.tensor((perturb_0 + feat)%2)) )\n",
    "    perturb_feat = parallel_apply_along_axis(join_string, axis=1, arr=perturb_feat)\n",
    "\n",
    "    return torch.tensor(parallel_matrix_operation(binary_to_float_vec, perturb_feat), dtype=torch.float)\n",
    "\n",
    "\n",
    "def OME_1(sample_feature_arr, eps=10.0, l=20, m=5):\n",
    "    \n",
    "    float_bin_2 = lambda x: float_to_binary(x, m, l-m-1)\n",
    "    float_to_binary_vec_2 = np.vectorize(float_bin_2)\n",
    "    bin_float_2 = lambda x: binary_to_float(x, m, l-m-1)\n",
    "    binary_to_float_vec_2 = np.vectorize(bin_float_2)\n",
    "\n",
    "    r = sample_feature_arr.shape[1]\n",
    "    \n",
    "    float_to_binary_vec = np.vectorize(float_bin)\n",
    "    binary_to_float_vec = np.vectorize(bin_float)\n",
    "\n",
    "    feat_tmp = float_to_binary_vec_2(sample_feature_arr)\n",
    "    feat = np.apply_along_axis(string_to_int, axis=1, arr=feat_tmp)\n",
    "\n",
    "    rl = r * l\n",
    "    alpha_ome = 100\n",
    "    index_matrix_1 = np.array([alpha_ome / (1+ alpha_ome), 1/ (1+alpha_ome**3)]*int(l/2)) # np.array(range(l))\n",
    "    index_matrix_0 = np.array([ (alpha_ome * np.exp(eps/rl)) /(1 + alpha_ome* np.exp(eps/rl))]*int(l) )\n",
    "    p_1 = np.tile(index_matrix_1, (sample_feature_arr.shape[0], r))\n",
    "    p_0 = np.tile(index_matrix_0, (sample_feature_arr.shape[0], r))\n",
    "\n",
    "    p_temp = np.random.rand(p_0.shape[0], p_0.shape[1])\n",
    "    perturb_0 = (p_temp > p_0).astype(int)\n",
    "    perturb_1 = (p_temp > p_1).astype(int)\n",
    "\n",
    "    perturb_feat = np.array(torch.where(torch.tensor(feat)>0, torch.tensor((perturb_1 + feat)%2), torch.tensor((perturb_0 + feat)%2)) )\n",
    "    perturb_feat = np.apply_along_axis(join_string, axis=1, arr=perturb_feat)\n",
    "\n",
    "    perturb_feat = binary_to_float_vec_2(perturb_feat)\n",
    "    return torch.squeeze(torch.tensor(perturb_feat, dtype=torch.float))#.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f5806fb-8c54-4b2f-8e66-b55ba6487027",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "506f5093-205f-49bc-95eb-71538210ef93",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AMIADatasetImagenet(Dataset):\n",
    "    \n",
    "    def __init__(self, target, transform, dataroot, train=True, imgroot=None, multiplier=100):\n",
    "        self.dataroot = dataroot\n",
    "        self.imgroot = imgroot\n",
    "        self.target = self.__get_target_full_path__(target)\n",
    "        self.target_multiplier = multiplier\n",
    "        self.transform = transform\n",
    "        self.train = train\n",
    "        if train:\n",
    "            self.valid_data = glob.glob(dataroot + 'val/*/*.JPEG', recursive=True)\n",
    "            self.length = len(target) * multiplier + len(self.valid_data)\n",
    "        else:\n",
    "            self.train_data = glob.glob(dataroot + 'train/*/*.JPEG', recursive=True)\n",
    "            # self.train_data_0 = np.array(self.train_data)\n",
    "            mask = np.ones(len(self.train_data), dtype=bool)\n",
    "#             mask[target] = False\n",
    "            for t in target:\n",
    "                for i in range(len(self.train_data)):\n",
    "                    if t in self.train_data[i]:\n",
    "                        mask[i] = False\n",
    "                        break\n",
    "            self.train_data = np.array(self.train_data)[mask, ...]\n",
    "            self.length = len(self.train_data) + len(target) * multiplier\n",
    "            \n",
    "    def __get_target_full_path__(self, target):\n",
    "        train_data = glob.glob(self.dataroot + 'train/*/*.JPEG', recursive=True)\n",
    "        for i in range(len(target)):\n",
    "            for j in range(len(train_data)):\n",
    "                if target[i] in train_data[j]:\n",
    "                    target[i] = train_data[j]\n",
    "                    break\n",
    "                    \n",
    "        return target\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.length\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        if self.train == False:\n",
    "            if idx / self.target_multiplier < len(self.target):\n",
    "                filename = self.target[int(idx / self.target_multiplier)]\n",
    "                # img_loc = os.path.join(self.dataroot, self.data_name[self.target[idx]])\n",
    "                class_id = torch.tensor(int(idx / self.target_multiplier))                \n",
    "            else:\n",
    "                idx -= len(self.target) * self.target_multiplier\n",
    "                filename = self.train_data[idx]\n",
    "                # img_loc = os.path.join(self.dataroot, self.data_name[self.valid_data[idx]])\n",
    "                class_id = torch.tensor(len(self.target))\n",
    "                \n",
    "        else:\n",
    "            if idx / self.target_multiplier < len(self.target):\n",
    "                filename = self.target[ int(idx / self.target_multiplier) ]\n",
    "                # img_loc = os.path.join(self.dataroot, self.data_name[self.target[idx]])\n",
    "                class_id = torch.tensor(int(idx / self.target_multiplier))                \n",
    "            else:\n",
    "                idx -= len(self.target) * self.target_multiplier\n",
    "                filename = self.valid_data[idx]\n",
    "                # img_loc = os.path.join(self.dataroot, self.data_name[self.valid_data[idx]])\n",
    "                class_id = torch.tensor(len(self.target))\n",
    "            \n",
    "        if self.imgroot:\n",
    "            img = Image.open(self.imgroot + filename)\n",
    "            img = self.transform(img)\n",
    "        else:\n",
    "            img = torch.tensor([])\n",
    "        \n",
    "        # img_tensor = img2vec.get_vec(img, tensor=True)\n",
    "        # img_tensor = torch.squeeze(img_tensor)\n",
    "        img_tensor = torch.load(filename)\n",
    "        \n",
    "        # img_tensor = img_tensor + s1.astype(np.float32)\n",
    "        \n",
    "        return img_tensor, class_id, img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "592b9710-9a5f-4fc9-b1c9-132fe0303099",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n"
     ]
    }
   ],
   "source": [
    "VEC_PATH='../imagenette2/imagenette_img2vec_resnet/'\n",
    "\n",
    "num_target = 1\n",
    "target = ['n01440764_10026']\n",
    "mech_setting = 'BitRand'\n",
    "eps = 6\n",
    "\n",
    "if mech_setting == 'BitRand':\n",
    "    mech = BitRand\n",
    "    mech_1 = BitRand_1\n",
    "elif mech_setting == 'OME':\n",
    "    mech = OME\n",
    "    mech_1 = OME_1\n",
    "else:\n",
    "    print('Error mech')\n",
    "    exit()\n",
    "\n",
    "print('Loading data...')\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(64),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "]) \n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(AMIADatasetImagenet(target, transform, VEC_PATH, False, imgroot=None, multiplier=1), shuffle=False, num_workers=0, batch_size=2000)\n",
    "\n",
    "x_test, y_test, _ = next(iter(test_loader))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dea2df0-55ce-4729-a507-0491d9f3b8ba",
   "metadata": {},
   "source": [
    "# Adversary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bc0b2b2f-4d38-43ff-a31b-89a38bd8630c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier(nn.Module):\n",
    "    def __init__(self, n_inputs, n_outputs):\n",
    "        super(Classifier, self).__init__()\n",
    "        self.fc1 = nn.Linear(n_inputs, 2*n_inputs)\n",
    "        self.fc2 = nn.Linear(2*n_inputs, 1)\n",
    "        \n",
    "    def adv_weights(self, target, tau, delta = 0):\n",
    "        K = torch.eye(self.fc1.in_features)\n",
    "        K = torch.cat((K, -K), 0)\n",
    "        self.fc1.weight.data = K\n",
    "        self.fc1.bias.data = torch.cat((-target - delta, target - delta), 0)\n",
    "        \n",
    "        self.fc2.weight.data[0] = -torch.ones(self.fc2.in_features)\n",
    "        self.fc2.bias.data[0] = tau\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        fc2 = self.fc2(x)\n",
    "        x = F.relu(fc2)\n",
    "        return x, fc2\n",
    "    \n",
    "model = Classifier(x_test.shape[1], num_target + 1)\n",
    "model.adv_weights(x_test[0], 0.0, 0.0)\n",
    "\n",
    "model = model.to(device)\n",
    "if device == 'cuda':\n",
    "    model = torch.nn.DataParallel(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4a46459-7b1b-4842-ad43-59ac7514200b",
   "metadata": {},
   "source": [
    "# Setup security game"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "92ccb41a-7005-490a-93ca-120d5440df00",
   "metadata": {},
   "outputs": [],
   "source": [
    "D = 64 # batch size\n",
    "times = 100 # num of runs\n",
    "NUM_PROCESS = 8\n",
    "from tqdm import tqdm\n",
    "\n",
    "def task_tpr(i):\n",
    "    x_test_threat = torch.cat((x_test[:1], x_test[np.random.randint(1, x_test.shape[0], D-1)]))\n",
    "    x_test_threat = BitRand_1(x_test_threat, eps, l=l, m=m)\n",
    "#     x_test_threat = OME_1(x_test_threat, eps, l=l, m=m) # Uncomment for OME\n",
    "    return x_test_threat\n",
    "\n",
    "def task_tnr(i):\n",
    "    x_test_threat = x_test[np.random.randint(1, x_test.shape[0], D)]\n",
    "    x_test_threat = BitRand_1(x_test_threat, eps, l=l, m=m)\n",
    "#     x_test_threat = OME_1(x_test_threat, eps, l=l, m=m) # Uncomment for OME\n",
    "    return x_test_threat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffd8458b-bb11-4e2b-9010-865f3a0dd21b",
   "metadata": {},
   "source": [
    "# Find Tau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "083a5b93-1ed9-4bf9-b827-5b5cb85f789b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:12<00:00,  7.82it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:17<00:00,  5.82it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:08<00:00, 12.34it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:12<00:00,  7.96it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:18<00:00,  5.54it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:00<00:00, 358.30it/s]\n"
     ]
    }
   ],
   "source": [
    "D = 64 # batch size\n",
    "times = 100 # num of runs\n",
    "NUM_PROCESS = 8\n",
    "\n",
    "model = Classifier(x_test.shape[1], num_target + 1)\n",
    "model.adv_weights(x_test[0], 0.0)\n",
    "\n",
    "model = model.to(device)\n",
    "if device == 'cuda':\n",
    "    model = torch.nn.DataParallel(model)\n",
    "\n",
    "# eps_taus = range(1,10) # to reproduce\n",
    "eps_taus = range(5,7) # to test\n",
    "taus = []\n",
    "for eps_tau in eps_taus:\n",
    "    \n",
    "    eps = eps_tau\n",
    "    with multiprocessing.Pool(processes=NUM_PROCESS) as pool:\n",
    "        x_tpr = list(tqdm(pool.imap_unordered(task_tpr, range(times), chunksize=5), total=times))\n",
    "        x_tnr = list(tqdm(pool.imap_unordered(task_tnr, range(times), chunksize=5), total=times))\n",
    "    \n",
    "    tmp_tau = 0\n",
    "    for x in tqdm(x_tpr):\n",
    "        out = model(x)[1]\n",
    "        out_pattern = out[0]\n",
    "        out_base = torch.mean(out[1:])\n",
    "        tmp_tau = tmp_tau + (out_pattern + out_base)/2 \n",
    "    tmp_tau = tmp_tau/len(x_tpr)\n",
    "    taus.append(tmp_tau)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9dfb8ba-204a-4d76-8afd-cd815248033c",
   "metadata": {},
   "source": [
    "# Attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0306390d-14f3-470d-af1f-3ca8d4d4c542",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle \n",
    "log_filename = 'FC_AMI_LDP_ImageNet.pkl'\n",
    "\n",
    "result_log = pd.DataFrame() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4ac2f4b2-f342-4c5c-bbfa-5fa27c2da00b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:12<00:00,  7.70it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:16<00:00,  6.03it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:00<00:00, 538.95it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:00<00:00, 558.21it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:12<00:00,  7.70it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:17<00:00,  5.63it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:00<00:00, 546.98it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:00<00:00, 562.86it/s]\n"
     ]
    }
   ],
   "source": [
    "D = 64 # batch size\n",
    "# runs = 20 # to reproduce \n",
    "runs = 1\n",
    "# games = 250 # to reproduce\n",
    "\n",
    "games = 100\n",
    "times = runs*games\n",
    "NUM_PROCESS = 8\n",
    "\n",
    "advs = []\n",
    "tprs = []\n",
    "tnrs = []\n",
    "\n",
    "for i in range(len(eps_taus)):\n",
    "    \n",
    "    eps = eps_taus[i]\n",
    "    model = Classifier(x_test.shape[1], num_target + 1)\n",
    "    model.adv_weights(x_test[0], -taus[i].detach(), 0.0) # Set tau in the FC-based adversary. If use OME, it should be ~ 440\n",
    "\n",
    "    model = model.to(device)\n",
    "    if device == 'cuda':\n",
    "        model = torch.nn.DataParallel(model)\n",
    "    \n",
    "    \n",
    "    with multiprocessing.Pool(processes=NUM_PROCESS) as pool:\n",
    "        x_tpr = list(tqdm(pool.imap_unordered(task_tpr, range(times), chunksize=5), total=times))\n",
    "        x_tnr = list(tqdm(pool.imap_unordered(task_tnr, range(times), chunksize=5), total=times))\n",
    "\n",
    "    \n",
    "    tpr = []\n",
    "    for x in tqdm(x_tpr):\n",
    "        out = model(x)[0]\n",
    "        if torch.sum(out > 0) > 0:\n",
    "            tpr.append(1)\n",
    "        else:\n",
    "            tpr.append(0)\n",
    "\n",
    "    tnr = []\n",
    "    for x in tqdm(x_tnr):\n",
    "        out = model(x)[0]\n",
    "        if torch.sum(out > 0) == 0:\n",
    "            tnr.append(1)\n",
    "        else:\n",
    "            tnr.append(0)\n",
    "    \n",
    "    for i in range(runs):\n",
    "        start_index = i*games\n",
    "        end_index = (i+1)*games\n",
    "\n",
    "        tp = sum(tpr[start_index:end_index])/games\n",
    "        tn = sum(tnr[start_index:end_index])/games\n",
    "        adv = tp/2 + tn/2\n",
    "        \n",
    "        report = {'eps' : eps,\n",
    "                'adv': adv}\n",
    "        \n",
    "        result_log = pd.concat([result_log, pd.DataFrame.from_records([report])])\n",
    "        with open(log_filename, 'wb') as logfile:\n",
    "            pickle.dump(result_log, logfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4c90d973-2e71-419f-8f8f-f0c17a35ac66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eps</th>\n",
       "      <th>adv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>0.955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   eps    adv\n",
       "0    5  0.955\n",
       "0    6  1.000"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_log"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bc9ab89-61b3-4943-a8a8-e46dc32a5f6e",
   "metadata": {},
   "source": [
    "# Simulate Theory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e155c951-34b0-41a0-badc-4f3d462df24c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle as pickle\n",
    "\n",
    "\n",
    "def find_delta_X(target, data):\n",
    "    min_dist = 500000\n",
    "    for i in range(data.shape[0]):\n",
    "        dist = sum(abs(target - data[i]))\n",
    "        if dist < min_dist:\n",
    "            min_dist = dist\n",
    "    return 1/2*min_dist\n",
    "\n",
    "target = x_test[0].clone()\n",
    "min_dist = find_delta_X(target, x_test[1:])\n",
    "\n",
    "run_id = '999'\n",
    "dataset = 'ImageNet'\n",
    "output_path = ''    \n",
    "    \n",
    "log_filename = os.path.join(output_path, \"log_{}_{}.pkl\".format(dataset, run_id))\n",
    "\n",
    "if os.path.isfile(log_filename):\n",
    "    sim_log = pd.read_pickle(log_filename)\n",
    "else:\n",
    "    sim_log = pd.DataFrame() \n",
    "\n",
    "no_runs = 50\n",
    "N = 100\n",
    "\n",
    "for _ in range(no_runs):\n",
    "\n",
    "    Pm = []\n",
    "    for eps in range(8,12):\n",
    "\n",
    "        dup = target.repeat([N,1])\n",
    "        ldp_dup = BitRand(dup, eps, l=l, m=m)\n",
    "\n",
    "\n",
    "        ldp_dist = []\n",
    "        for i in range(N):\n",
    "            dist = sum(abs(target - ldp_dup[i]))\n",
    "            if dist > min_dist:\n",
    "                ldp_dist.append(1)\n",
    "            else:\n",
    "                ldp_dist.append(0)\n",
    "                \n",
    "        Pm.append(np.sum(np.asarray(ldp_dist))/N)\n",
    "    \n",
    "        result = {'Run ID': run_id,\n",
    "                  'Dataset': dataset,\n",
    "                  'Prob' : np.sum(np.asarray(ldp_dist))/N,\n",
    "                  'Eps': eps}\n",
    "        \n",
    "        sim_log = pd.concat([sim_log, pd.DataFrame.from_records([result])])\n",
    "#         with open(log_filename, 'wb') as logfile:\n",
    "#             pickle.dump(training_log, logfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2dbf737e-05e9-4f8b-85e4-eaa14b743537",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot: xlabel='Eps', ylabel='Success rate'>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "# sim_log = pd.read_pickle('log_training_ImageNet_l20.pkl')\n",
    "D = 100\n",
    "size_X = 1000\n",
    "sim_log['Success min'] =  0.5\n",
    "sim_log['Success rate'] =  (2 - sim_log['Prob']*(D + size_X)/size_X)/2\n",
    "sim_log['Success rate'] = sim_log[['Success rate', 'Success min']].max(axis=1)\n",
    "\n",
    "sns.lineplot( x=\"Eps\", y=\"Success rate\", \n",
    "                     data=sim_log, \n",
    "                     palette = 'tab10',\n",
    "                     markers=True,\n",
    "                     legend=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8f661d9-7b88-40d0-ad0d-24b3763e9323",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
